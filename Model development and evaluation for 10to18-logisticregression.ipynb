{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "def specificity(y_ture,y_pred):\n",
    "    MCM = confusion_matrix(y_ture, y_pred)\n",
    "    tn_sum = MCM[0, 0]\n",
    "    fp_sum = MCM[0, 1]\n",
    "\n",
    "    tp_sum = MCM[1, 1]\n",
    "    fn_sum = MCM[1, 0]\n",
    "\n",
    "    Condition_negative = tn_sum + fp_sum\n",
    "\n",
    "    Specificity = tn_sum / Condition_negative\n",
    "\n",
    "    return Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4db391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import pickle as pl \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score,make_scorer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#build the series of talent prediction models\n",
    "\n",
    "file_afterlabel = pandas.read_excel(\"The Shanghai data with labels.xlsx\")\n",
    "\n",
    "\n",
    "file1_1_afterlabel = file_afterlabel.loc[file_afterlabel[\"Sex\"]==0]#select the female\n",
    "file2_1_afterlabel = file_afterlabel.loc[file_afterlabel[\"Sex\"]==1]#select the male\n",
    "\n",
    "\n",
    "\n",
    "file1_1_afterlabel_years = [file1_1_afterlabel.loc[round(file1_1_afterlabel[\"Age\"]) == i] for i in range(10,19)]\n",
    "file2_1_afterlabel_years = [file2_1_afterlabel.loc[round(file2_1_afterlabel[\"Age\"]) == i] for i in range(10,19)]\n",
    "#oversampling\n",
    "for k in range(9):\n",
    "    x_lin = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==1]\n",
    "    num_range = x_lin.shape[0]\n",
    "    x_lin.index = range(num_range)\n",
    "    file1_1_afterlabel_years[k] = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==0]\n",
    "    num_oversampling = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==0].shape[0]\n",
    "    for i in range(num_oversampling):\n",
    "        x_lin_lin = x_lin.loc[np.round(random.uniform(0,num_range-1))]\n",
    "        file1_1_afterlabel_years[k] = pandas.concat([file1_1_afterlabel_years[k],pandas.DataFrame(x_lin_lin).T],axis=0)    \n",
    "\n",
    "for k in range(9):\n",
    "    x_lin = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==1]\n",
    "    num_range = x_lin.shape[0]\n",
    "    x_lin.index = range(num_range)\n",
    "    file2_1_afterlabel_years[k] = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==0]\n",
    "    num_oversampling = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==0].shape[0]\n",
    "    for i in range(num_oversampling):\n",
    "        x_lin_lin = x_lin.loc[np.round(random.uniform(0,num_range-1))]\n",
    "        file2_1_afterlabel_years[k] = pandas.concat([file2_1_afterlabel_years[k],pandas.DataFrame(x_lin_lin).T],axis=0)    \n",
    "\n",
    "#re-order\n",
    "for k in range(9):\n",
    "    file1_1_afterlabel_years[k].index = range(file1_1_afterlabel_years[k].shape[0])\n",
    "    file2_1_afterlabel_years[k].index = range(file2_1_afterlabel_years[k].shape[0])\n",
    "    \n",
    "    \n",
    "X_12_0_new_afterlabel_years = [file1_1_afterlabel_years[i].loc[:][file1_1_afterlabel_years[i].columns[1:23]] for i in range(9)]\n",
    "X_12_1_new_afterlabel_years = [file2_1_afterlabel_years[i].loc[:][file2_1_afterlabel_years[i].columns[1:23]] for i in range(9)]\n",
    "\n",
    "\n",
    "\n",
    "y_12_0_new_afterlabel_years = [file1_1_afterlabel_years[i].loc[:][\"Lable\"]for i in range(9)]\n",
    "y_12_1_new_afterlabel_years = [file2_1_afterlabel_years[i].loc[:][\"Lable\"]for i in range(9)]\n",
    "\n",
    "#construct the empty list\n",
    "X_12_0_new_afterlabel_train = [[] for i in range(9)]  \n",
    "X_12_0_new_afterlabel_test  = [[] for i in range(9)]\n",
    "y_12_0_new_afterlabel_train = [[] for i in range(9)]\n",
    "y_12_0_new_afterlabel_test = [[] for i in range(9)]\n",
    "\n",
    "X_12_1_new_afterlabel_train = [[] for i in range(9)]  \n",
    "X_12_1_new_afterlabel_test  = [[] for i in range(9)]\n",
    "y_12_1_new_afterlabel_train = [[] for i in range(9)]\n",
    "y_12_1_new_afterlabel_test = [[] for i in range(9)]\n",
    "\n",
    "for i in range(9):\n",
    "    X_12_0_new_afterlabel_train[i],X_12_0_new_afterlabel_test[i],y_12_0_new_afterlabel_train[i],y_12_0_new_afterlabel_test[i] = train_test_split(\n",
    "    X_12_0_new_afterlabel_years[i],y_12_0_new_afterlabel_years[i],test_size=0.3,random_state=2022,stratify=y_12_0_new_afterlabel_years[i])\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    X_12_1_new_afterlabel_train[i],X_12_1_new_afterlabel_test[i],y_12_1_new_afterlabel_train[i],y_12_1_new_afterlabel_test[i] = train_test_split(\n",
    "    X_12_1_new_afterlabel_years[i],y_12_1_new_afterlabel_years[i],test_size=0.3,random_state=2022,stratify=y_12_1_new_afterlabel_years[i])\n",
    "\n",
    "\n",
    "log_10_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_10_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_11_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_11_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_12_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_12_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_13_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_13_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_14_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_14_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_15_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_15_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_16_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_16_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_17_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_17_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_18_0 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "log_18_1 = LogisticRegressionCV(scoring=make_scorer(f1_score),refit=True,penalty = \"l1\",solver='liblinear',max_iter=10000,cv = 5,class_weight=\"balanced\",n_jobs=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train the series of models\n",
    "log_10_0.fit(X_12_0_new_afterlabel_train[0],y_12_0_new_afterlabel_train[0].astype(\"int\"))\n",
    "log_10_1.fit(X_12_1_new_afterlabel_train[0],y_12_1_new_afterlabel_train[0].astype(\"int\"))\n",
    "\n",
    "log_11_0.fit(X_12_0_new_afterlabel_train[1],y_12_0_new_afterlabel_train[1].astype(\"int\"))\n",
    "log_11_1.fit(X_12_1_new_afterlabel_train[1],y_12_1_new_afterlabel_train[1].astype(\"int\"))\n",
    "\n",
    "log_12_0.fit(X_12_0_new_afterlabel_train[2],y_12_0_new_afterlabel_train[2].astype(\"int\"))\n",
    "log_12_1.fit(X_12_1_new_afterlabel_train[2],y_12_1_new_afterlabel_train[2].astype(\"int\"))\n",
    "\n",
    "log_13_0.fit(X_12_0_new_afterlabel_train[3],y_12_0_new_afterlabel_train[3].astype(\"int\"))\n",
    "log_13_1.fit(X_12_1_new_afterlabel_train[3],y_12_1_new_afterlabel_train[3].astype(\"int\"))\n",
    "\n",
    "log_14_0.fit(X_12_0_new_afterlabel_train[4],y_12_0_new_afterlabel_train[4].astype(\"int\"))\n",
    "log_14_1.fit(X_12_1_new_afterlabel_train[4],y_12_1_new_afterlabel_train[4].astype(\"int\"))\n",
    "\n",
    "log_15_0.fit(X_12_0_new_afterlabel_train[5],y_12_0_new_afterlabel_train[5].astype(\"int\"))\n",
    "log_15_1.fit(X_12_1_new_afterlabel_train[5],y_12_1_new_afterlabel_train[5].astype(\"int\"))\n",
    "\n",
    "log_16_0.fit(X_12_0_new_afterlabel_train[6],y_12_0_new_afterlabel_train[6].astype(\"int\"))\n",
    "log_16_1.fit(X_12_1_new_afterlabel_train[6],y_12_1_new_afterlabel_train[6].astype(\"int\"))\n",
    "\n",
    "log_17_0.fit(X_12_0_new_afterlabel_train[7],y_12_0_new_afterlabel_train[7].astype(\"int\"))\n",
    "log_17_1.fit(X_12_1_new_afterlabel_train[7],y_12_1_new_afterlabel_train[7].astype(\"int\"))\n",
    "\n",
    "log_18_0.fit(X_12_0_new_afterlabel_train[8],y_12_0_new_afterlabel_train[8].astype(\"int\"))\n",
    "log_18_1.fit(X_12_1_new_afterlabel_train[8],y_12_1_new_afterlabel_train[8].astype(\"int\"))\n",
    "\n",
    "\n",
    "with open('log_10_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_10_0, f)\n",
    "with open('log_10_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_10_1, f)\n",
    "    \n",
    "with open('log_11_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_11_0, f)\n",
    "with open('log_11_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_11_1, f)\n",
    "\n",
    "with open('log_12_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_12_0, f)\n",
    "with open('log_12_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_12_1, f)\n",
    "    \n",
    "with open('log_13_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_13_0, f)\n",
    "with open('log_13_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_13_1, f)\n",
    "    \n",
    "with open('log_14_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_14_0, f)\n",
    "with open('log_14_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_14_1, f)\n",
    "    \n",
    "with open('log_15_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_15_0, f)\n",
    "with open('log_15_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_15_1, f)\n",
    "    \n",
    "with open('log_16_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_16_0, f)\n",
    "with open('log_16_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_16_1, f)\n",
    "    \n",
    "with open('log_17_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_17_0, f)\n",
    "with open('log_17_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_17_1, f)\n",
    "    \n",
    "with open('log_18_0.pkl', 'wb') as f:\n",
    "    pickle.dump(log_18_0, f)\n",
    "with open('log_18_1.pkl', 'wb') as f:\n",
    "    pickle.dump(log_18_1, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beccb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        召回率       精准率       准确率       特异性     AUC面积       f1值\n",
      "0  0.714286  0.312500  0.628571  0.607143  0.775510  0.434783\n",
      "1  0.750000  0.391304  0.725806  0.720000  0.848333  0.514286\n",
      "2  0.812500  0.464286  0.756757  0.741379  0.879310  0.590909\n",
      "3  0.900000  0.428571  0.811594  0.796610  0.906780  0.580645\n",
      "4  0.625000  0.416667  0.803922  0.837209  0.869186  0.500000\n",
      "5  0.714286  0.312500  0.675000  0.666667  0.783550  0.434783\n",
      "6  1.000000  0.500000  0.821429  0.782609  0.843478  0.666667\n",
      "7  1.000000  0.545455  0.800000  0.736842  0.850877  0.705882\n",
      "8  0.750000  0.600000  0.785714  0.800000  0.850000  0.666667\n",
      "        召回率       精准率       准确率       特异性     AUC面积       f1值\n",
      "0  0.800000  0.235294  0.674419  0.657895  0.805263  0.363636\n",
      "1  0.833333  0.400000  0.773333  0.761905  0.888889  0.540541\n",
      "2  0.727273  0.250000  0.696629  0.692308  0.708625  0.372093\n",
      "3  0.666667  0.228571  0.693069  0.696629  0.753745  0.340426\n",
      "4  0.666667  0.320000  0.783505  0.800000  0.721569  0.432432\n",
      "5  0.800000  0.275862  0.708861  0.695652  0.810145  0.410256\n",
      "6  0.777778  0.291667  0.641509  0.613636  0.750000  0.424242\n",
      "7  0.714286  0.277778  0.605263  0.580645  0.626728  0.400000\n",
      "8  1.000000  0.444444  0.814815  0.782609  0.880435  0.615385\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import pickle as pl \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "file_afterlabel = pandas.read_excel(\"The Shanghai data with labels.xlsx\")\n",
    "\n",
    "\n",
    "file1_1_afterlabel = file_afterlabel.loc[file_afterlabel[\"Sex\"]==0]#select the female\n",
    "file2_1_afterlabel = file_afterlabel.loc[file_afterlabel[\"Sex\"]==1]#select the male\n",
    "\n",
    "#进行oversampling\n",
    "for k in range(9):\n",
    "    x_lin = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==1]\n",
    "    num_range = x_lin.shape[0]\n",
    "    x_lin.index = range(num_range)\n",
    "    file1_1_afterlabel_years[k] = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==0]\n",
    "    num_oversampling = file1_1_afterlabel_years[k].loc[file1_1_afterlabel_years[k][\"Label\"]==0].shape[0]\n",
    "    for i in range(num_oversampling):\n",
    "        x_lin_lin = x_lin.loc[np.round(random.uniform(0,num_range-1))]\n",
    "        file1_1_afterlabel_years[k] = pandas.concat([file1_1_afterlabel_years[k],pandas.DataFrame(x_lin_lin).T],axis=0)    \n",
    "\n",
    "for k in range(9):\n",
    "    x_lin = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==1]\n",
    "    num_range = x_lin.shape[0]\n",
    "    x_lin.index = range(num_range)\n",
    "    file2_1_afterlabel_years[k] = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==0]\n",
    "    num_oversampling = file2_1_afterlabel_years[k].loc[file2_1_afterlabel_years[k][\"Label\"]==0].shape[0]\n",
    "    for i in range(num_oversampling):\n",
    "        x_lin_lin = x_lin.loc[np.round(random.uniform(0,num_range-1))]\n",
    "        file2_1_afterlabel_years[k] = pandas.concat([file2_1_afterlabel_years[k],pandas.DataFrame(x_lin_lin).T],axis=0)    \n",
    "\n",
    "#re-order\n",
    "for k in range(9):\n",
    "    file1_1_afterlabel_years[k].index = range(file1_1_afterlabel_years[k].shape[0])\n",
    "    file2_1_afterlabel_years[k].index = range(file2_1_afterlabel_years[k].shape[0])\n",
    "\n",
    "index_name = file1_1_afterlabel.columns[1:23]\n",
    "\n",
    "file1_1_afterlabel_years = [file1_1_afterlabel.loc[round(file1_1_afterlabel[\"Age\"]) == i] for i in range(10,19)]#分别选出来10-18岁\n",
    "file2_1_afterlabel_years = [file2_1_afterlabel.loc[round(file2_1_afterlabel[\"Age\"]) == i] for i in range(10,19)]\n",
    "\n",
    "X_12_0_new_afterlabel_years = [file1_1_afterlabel_years[i].loc[:][file1_1_afterlabel_years[i].columns[1:23]] for i in range(9)]\n",
    "X_12_1_new_afterlabel_years = [file2_1_afterlabel_years[i].loc[:][file2_1_afterlabel_years[i].columns[1:23]] for i in range(9)]\n",
    "\n",
    "\n",
    "\n",
    "y_12_0_new_afterlabel_years = [file1_1_afterlabel_years[i].loc[:][\"Label\"]for i in range(9)]\n",
    "y_12_1_new_afterlabel_years = [file2_1_afterlabel_years[i].loc[:][\"Label\"]for i in range(9)]\n",
    "\n",
    "X_12_0_new_afterlabel_train = [[] for i in range(9)]  \n",
    "X_12_0_new_afterlabel_test  = [[] for i in range(9)]\n",
    "y_12_0_new_afterlabel_train = [[] for i in range(9)]\n",
    "y_12_0_new_afterlabel_test = [[] for i in range(9)]\n",
    "\n",
    "X_12_1_new_afterlabel_train = [[] for i in range(9)]  \n",
    "X_12_1_new_afterlabel_test  = [[] for i in range(9)]\n",
    "y_12_1_new_afterlabel_train = [[] for i in range(9)]\n",
    "y_12_1_new_afterlabel_test = [[] for i in range(9)]\n",
    "#set random seed\n",
    "for i in range(9):\n",
    "    X_12_0_new_afterlabel_train[i],X_12_0_new_afterlabel_test[i],y_12_0_new_afterlabel_train[i],y_12_0_new_afterlabel_test[i] = train_test_split(\n",
    "    X_12_0_new_afterlabel_years[i],y_12_0_new_afterlabel_years[i],test_size=0.3,random_state=2022,stratify=y_12_0_new_afterlabel_years[i])\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    X_12_1_new_afterlabel_train[i],X_12_1_new_afterlabel_test[i],y_12_1_new_afterlabel_train[i],y_12_1_new_afterlabel_test[i] = train_test_split(\n",
    "    X_12_1_new_afterlabel_years[i],y_12_1_new_afterlabel_years[i],test_size=0.3,random_state=2022,stratify=y_12_1_new_afterlabel_years[i])\n",
    "\n",
    "\n",
    "\n",
    "y = [[] for i in range(9)]\n",
    "y_1 = [[] for i in range(9)]\n",
    "\n",
    "proba_test = [[] for i in range(9)]\n",
    "proba_test_1 = [[] for i in range(9)]\n",
    "\n",
    "y_pred = [[] for i in range(9)]\n",
    "y_pred_1 = [[] for i in range(9)]\n",
    "for i in range(9):\n",
    "    if i == 0:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_10_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_10_0.predict_proba(X_12_0_new_afterlabel_test[i])\n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_10_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_10_1.predict_proba(X_12_1_new_afterlabel_test[i])\n",
    "    if i == 1:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_11_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_11_0.predict_proba(X_12_0_new_afterlabel_test[i])        \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_11_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_11_1.predict_proba(X_12_1_new_afterlabel_test[i])\n",
    "    if i == 2:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_12_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_12_0.predict_proba(X_12_0_new_afterlabel_test[i])               \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_12_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_12_1.predict_proba(X_12_1_new_afterlabel_test[i])\n",
    "    if i == 3:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_13_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_13_0.predict_proba(X_12_0_new_afterlabel_test[i])            \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_13_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_13_1.predict_proba(X_12_1_new_afterlabel_test[i])        \n",
    "    if i == 4:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_14_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_14_0.predict_proba(X_12_0_new_afterlabel_test[i])               \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_14_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_14_1.predict_proba(X_12_1_new_afterlabel_test[i])            \n",
    "    if i == 5:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_15_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_15_0.predict_proba(X_12_0_new_afterlabel_test[i])                 \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_15_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_15_1.predict_proba(X_12_1_new_afterlabel_test[i])        \n",
    "    if i == 6:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_16_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_16_0.predict_proba(X_12_0_new_afterlabel_test[i])               \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_16_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_16_1.predict_proba(X_12_1_new_afterlabel_test[i])       \n",
    "    if i == 7:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_17_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_17_0.predict_proba(X_12_0_new_afterlabel_test[i])                      \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_17_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_17_1.predict_proba(X_12_1_new_afterlabel_test[i])     \n",
    "    if i == 8:\n",
    "        y[i] = y_12_0_new_afterlabel_test[i]\n",
    "        y_pred[i] = log_18_0.predict(X_12_0_new_afterlabel_test[i])\n",
    "        proba_test[i] = log_18_0.predict_proba(X_12_0_new_afterlabel_test[i])           \n",
    "        \n",
    "        y_1[i] = y_12_1_new_afterlabel_test[i]\n",
    "        y_pred_1[i] = log_18_1.predict(X_12_1_new_afterlabel_test[i])\n",
    "        proba_test_1[i] = log_18_1.predict_proba(X_12_1_new_afterlabel_test[i])     \n",
    "        \n",
    "for i in range(9):\n",
    "    roc_sum = [roc_curve(y[i],proba_test[i][:,1]) for i in range(9)]\n",
    "    fpr_test = [roc_sum[i][0] for i in range(9)]\n",
    "    tpr_test = [roc_sum[i][1] for i in range(9)]\n",
    "    threshold = [roc_sum[i][2] for i in range(9)]\n",
    "    roc_auc_test = [auc(fpr_test[i],tpr_test[i]) for i in range(9)] #calculate\n",
    "    \n",
    "    roc_sum_1 = [roc_curve(y_1[i],proba_test_1[i][:,1]) for i in range(9)]\n",
    "    fpr_test_1 = [roc_sum_1[i][0] for i in range(9)]\n",
    "    tpr_test_1 = [roc_sum_1[i][1] for i in range(9)]\n",
    "    threshold_1 = [roc_sum_1[i][2] for i in range(9)]\n",
    "    roc_auc_test_1 = [auc(fpr_test_1[i],tpr_test_1[i]) for i in range(9)]\n",
    "        \n",
    "data_0 = pandas.DataFrame({\"Recall\":[recall_score(y[i], y_pred[i]) for i in range(9)],\"Precision\":[precision_score(y[i], y_pred[i]) for i in range(9)],\n",
    "                         \"Accuracy\":[accuracy_score(y[i], y_pred[i]) for i in range(9)],\"Specificity\":[specificity(y[i], y_pred[i]) for i in range(9)],\n",
    "                        \"AUC\":roc_auc_test,\"F1 score\":[f1_score(y[i], y_pred[i]) for i in range(9)]})\n",
    "data_1 = pandas.DataFrame({\"Recall\":[recall_score(y_1[i], y_pred_1[i]) for i in range(9)],\"Precision\":[precision_score(y_1[i], y_pred_1[i]) for i in range(9)],\n",
    "                         \"Accuracy\":[accuracy_score(y_1[i], y_pred_1[i]) for i in range(9)],\"Specificity\":[specificity(y_1[i], y_pred_1[i]) for i in range(9)],\n",
    "                         \"AUC\":roc_auc_test_1,\"F1 score\":[f1_score(y_1[i], y_pred_1[i]) for i in range(9)]})\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
